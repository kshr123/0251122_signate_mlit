# exp011: 損失関数の比較実験

## 概要

損失関数・サンプル重み付けの効果を検証する実験。
低価格帯（特に広面積×築古）の予測精度改善を目指す。

## 損失関数の解説

### MSE（Mean Squared Error）- ベースライン
```
損失:     L = mean((y - ŷ)²)
勾配:     ∂L/∂ŷ = 2(ŷ - y)
ヘシアン: ∂²L/∂ŷ² = 2
```
- **特徴**: 標準的な二乗誤差。大きな誤差を強くペナルティ
- **メリット**: 微分が簡単、最適化が安定
- **デメリット**: 外れ値に敏感、相対誤差を考慮しない
- **用途**: 一般的な回帰タスクのベースライン
- **ロジック**: 誤差の2乗なので、誤差が2倍になるとペナルティは4倍。高価格物件の絶対誤差が大きくなりやすく、そちらの最適化が優先される

### Huber Loss（ロバスト回帰）
```
損失:     L = 0.5 * (y - ŷ)²           (|y - ŷ| ≤ δ の場合)
          L = δ * (|y - ŷ| - 0.5 * δ)  (|y - ŷ| > δ の場合)
勾配:     ∂L/∂ŷ = (ŷ - y)              (|y - ŷ| ≤ δ)
          ∂L/∂ŷ = δ * sign(ŷ - y)      (|y - ŷ| > δ)
ヘシアン: ∂²L/∂ŷ² = 1                   (|y - ŷ| ≤ δ)
          ∂²L/∂ŷ² = 0                   (|y - ŷ| > δ)
```
- **特徴**: 小さい誤差ではMSE、大きい誤差ではMAEのように振る舞う
- **パラメータ**: `alpha`（δ）: 閾値。小さいほどMAEに近づく
- **メリット**: 外れ値に対してロバスト
- **デメリット**: 相対誤差は考慮しない
- **用途**: データに外れ値が含まれる場合
- **ロジック**: 誤差がδを超えると線形（MAE）になるため、外れ値の影響が抑制される。δ=1.0がデフォルト。log1p変換後のスケールでは、元の価格で約2.7倍の誤差に相当

### Quantile Loss（分位点回帰）
```
損失:     L = α * (y - ŷ)        (y > ŷ の場合: 過小予測)
          L = (1-α) * (ŷ - y)    (y ≤ ŷ の場合: 過大予測)
勾配:     ∂L/∂ŷ = -α             (y > ŷ)
          ∂L/∂ŷ = (1-α)          (y ≤ ŷ)
ヘシアン: ∂²L/∂ŷ² = 0            (絶対値関数のため不連続)
```
- **特徴**: 過大予測と過小予測のペナルティを非対称にする
- **パラメータ**: `alpha`: 0.5=中央値、<0.5=過小予測を厳しく、>0.5=過大予測を厳しく
- **メリット**: 予測のバイアスを制御可能
- **デメリット**: 最適なalphaの選定が必要
- **用途**: 低価格帯で過大予測を避けたい場合（alpha < 0.5）
- **ロジック**: α=0.3の場合、過小予測のペナルティは0.3、過大予測は0.7。つまり過大予測を2.3倍厳しく罰する。低価格物件を高く予測してしまうのを抑制したい場合に有効

### Sample Weight（サンプル重み付け）
```
損失:     L = mean(w * (y - ŷ)²)
          w = f(y) : 目的変数に基づく重み
勾配:     ∂L/∂ŷ = 2w(ŷ - y)        (MSEと同じだが重み付き)
ヘシアン: ∂²L/∂ŷ² = 2w
```
- **特徴**: サンプルごとに重みを付けて損失を計算
- **重み関数の例**:
  - `inverse`: w = 1/y（低価格ほど重い）
  - `sqrt_inverse`: w = 1/√y（やや緩やか）
  - `log_inverse`: w = 1/log(y+1)（さらに緩やか）
  - `threshold`: y < 閾値 → 重み大、それ以外 → 重み小
- **メリット**: 既存の損失関数をそのまま使える
- **デメリット**: 重み設計に試行錯誤が必要
- **用途**: 特定の価格帯を重点的に改善したい場合
- **ロジック**:
  - inverse例: 500万円(w=0.0002) vs 5000万円(w=0.00002) → 低価格は10倍の重み
  - threshold例: 1000万円未満はw=2.0、以上はw=1.0 → 低価格帯を2倍重視
  - 損失関数自体は変えないので、early stoppingとの相性が良い

### MAPE Objective（相対誤差直接最適化）
```
損失:     L = mean(|y - ŷ| / |y|) * 100
勾配:     ∂L/∂ŷ = sign(ŷ - y) / |y|
ヘシアン: ∂²L/∂ŷ² ≈ hessian_const（定数で近似、MAPEは絶対値を含むため二次微分が存在しない）
```
- **特徴**: MAPEを直接最小化するカスタム目的関数
- **パラメータ**: `hessian_const`: ヘシアン近似値（デフォルト: 1.0）
  | 値 | 挙動 |
  |----|------|
  | 0.1 | 積極的な学習（更新幅大、不安定リスク） |
  | **1.0** | **バランス良い（推奨）** |
  | 2.0 | 慎重な学習（MSEと同等の更新幅） |
- **メリット**: 評価指標と損失関数が一致
- **デメリット**: ヘシアンが存在せず近似が必要、学習が不安定になりやすい
- **用途**: MAPEを最小化したい場合（本コンペの評価指標）
- **ロジック**:
  - 勾配は1/|y|に比例するため、低価格ほど勾配が大きくなる
  - 例: 500万円は勾配0.0002、5000万円は0.00002 → 低価格は10倍の更新量
  - ヘシアンは定数近似で学習ステップサイズを制御
  - log1p変換後に適用するため、元の価格スケールでの相対誤差とは異なる点に注意

### Focal Loss（難サンプル重視）
```
損失:     L = mean(w * residual²)
          w = |residual|^γ = |y - ŷ|^γ
勾配:     ∂L/∂ŷ = 2w * (ŷ - y)
ヘシアン: ∂²L/∂ŷ² ≈ 2w（簡略化した近似）
```
- **特徴**: 予測誤差が大きいサンプル（難サンプル）に高い重みを付ける
- **パラメータ**: `gamma`: フォーカシングパラメータ（デフォルト: 2.0）
  | 値 | 誤差0.1 vs 1.0の重み比 | 挙動 |
  |----|------------------------|------|
  | 0 | 1:1 | MSEと同じ |
  | 1.0 | 1:10 | 控えめ、外れ値リスク低 |
  | **2.0** | **1:100** | **デフォルト、分類Focal Lossと同じ** |
  | 3.0 | 1:1000 | 積極的、難サンプル重視 |
- **メリット**: 予測が難しいサンプルの学習を強化
- **デメリット**: 外れ値にも高い重みが付く可能性
- **用途**: 特定のセグメントで予測誤差が大きい場合
- **ロジック**:
  - γ=2の場合、誤差0.1のサンプルはw=0.01、誤差1.0はw=1.0 → 100倍の差
  - 学習初期は難サンプルに集中し、徐々に全体を均等に学習
  - 分類タスクのFocal Lossを回帰に応用したもの
  - 外れ値と本当に予測困難なサンプルを区別できない点に注意

## log1p変換との組み合わせ

本実験ではすべての損失関数を **log1p変換後** の目的変数に対して適用：

```python
y_train_transformed = np.log1p(y_train)  # 学習時
y_pred = np.expm1(model.predict(X))      # 予測時に逆変換
```

- **理由**: 価格の分布が右に歪んでいるため、log変換で正規化
- **効果**: 低価格帯の相対的な重要度が自然に高まる

## 実験フェーズ

### Phase 1: パラメータ変更のみ
| 実験名 | 全体MAPE | 備考 |
|--------|----------|------|
| **huber** | **12.17%** | **最良** |
| mse | 12.19% | ベースライン（exp010再現） |
| sample_weight | 12.24% | inverse重み付け |
| quantile (α=0.3) | スキップ | ヘシアン=0で学習不安定 |

### Phase 2: カスタム目的関数
| 実験名 | 全体MAPE | 備考 |
|--------|----------|------|
| focal (γ=2.0) | 12.58% | 難サンプル重視 |
| mape | 12.83% | MAPE直接最適化 |

### Phase 3: アンサンブル・スタッキング

#### 3-1. 単純アンサンブル
| 方式 | 全体MAPE | 備考 |
|------|----------|------|
| 単純平均 | TBD | 全モデルの予測を平均 |
| 重み付き平均 | TBD | OOFでMAPE最小化する重みを探索 |

#### 3-2. スタッキング
| メタモデル | 全体MAPE | 備考 |
|------------|----------|------|
| Ridge | TBD | L2正則化線形回帰 |
| LightGBM | TBD | 非線形メタモデル |

**スタッキング概要**:
- **Level 0**: MSE, Huber, sample_weight 等の各モデル
- **Level 1**: Level 0のOOF予測を特徴量としてメタモデルを学習
- **予測時**: Level 0で各モデル予測 → Level 1で統合

**スタッキングの利点**:
- 各モデルの予測傾向の違いを活用（MSE=高価格重視、sample_weight=低価格重視）
- 重み付き平均より柔軟な組み合わせが可能
- 価格帯ごとに異なるモデルを重視することも学習可能

## 実行方法

```bash
cd 06_experiments/exp011_loss_function
source ../../.venv/bin/activate

# Phase 1
PYTHONPATH=../../04_src:code python code/train.py --objective huber
PYTHONPATH=../../04_src:code python code/train.py --objective quantile --alpha 0.3
PYTHONPATH=../../04_src:code python code/train.py --objective sample_weight --weight-transform inverse

# Phase 2
PYTHONPATH=../../04_src:code python code/train.py --objective mape
PYTHONPATH=../../04_src:code python code/train.py --objective focal --gamma 2.0

# 前処理済みデータを再利用（2回目以降）
PYTHONPATH=../../04_src:code python code/train.py --objective quantile --alpha 0.3 --features-dir outputs/run_huber_20251128_145728/
```

テスト実行：
```bash
PYTHONPATH=../../04_src:code python code/train.py --objective huber --test
```

## 考察

### 結果サマリー

| 順位 | 損失関数 | CV MAPE | 備考 |
|------|----------|---------|------|
| 1 | **Huber** | **12.17%** | 最良、外れ値にロバスト |
| 2 | MSE | 12.19% | ベースライン |
| 3 | sample_weight | 12.24% | inverse重み付け |
| 4 | Focal (γ=2.0) | 12.58% | 難サンプル重視 |
| 5 | MAPE | 12.83% | MAPE直接最適化 |

### 考察

1. **Huberが最良（12.17%）**
   - MSEより0.02%改善（微小だが一貫して良い）
   - 外れ値の影響を抑制し、安定した学習

2. **カスタム目的関数は効果薄**
   - MAPE直接最適化: ヘシアン近似の影響で学習が不安定
   - Focal Loss: 難サンプルに過度に重みを付け、全体が悪化

3. **log1p変換が既に効いている**
   - log1p変換により低価格帯の相対的重要度が自然に高まる
   - 追加のsample_weight等の効果は限定的

4. **予測間相関が高い**
   - 各モデルの予測は0.99以上の相関
   - 単純平均の改善効果は期待薄

### Next Steps
- Phase 3: スタッキングで各モデルの予測傾向を組み合わせる
- Huberをメイン損失関数として採用
