"""
exp002 EDA: äºˆæ¸¬èª¤å·®åˆ†æ

- äºˆæ¸¬èª¤å·®ã®å¤§ãã„ã‚µãƒ³ãƒ—ãƒ«åˆ†æ
- ç‰¹å¾´é‡é‡è¦åº¦ã®å¯è¦–åŒ–
- éƒ½é“åºœçœŒãƒ»å¸‚åŒºç”ºæ‘åˆ¥ã®èª¤å·®åˆ†æï¼ˆãƒã‚¹ã‚¿ãƒ¼çªåˆï¼‰
"""

import sys
from pathlib import Path

project_root = Path(__file__).resolve().parents[3]
sys.path.insert(0, str(project_root / "04_src"))

import polars as pl
import numpy as np
import matplotlib.pyplot as plt
import japanize_matplotlib

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
output_dir = Path(__file__).parent.parent / "outputs"
notebook_output = Path(__file__).parent / "figures"
notebook_output.mkdir(exist_ok=True)

# æœ€æ–°ã®OOFäºˆæ¸¬ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
oof_files = sorted(output_dir.glob("oof_predictions_*.csv"))
latest_oof = oof_files[-1] if oof_files else None

importance_files = sorted(output_dir.glob("feature_importance_*.csv"))
latest_importance = importance_files[-1] if importance_files else None

print("=" * 60)
print("exp002 EDA: äºˆæ¸¬èª¤å·®åˆ†æ")
print("=" * 60)

# ===== 1. OOFäºˆæ¸¬èª­ã¿è¾¼ã¿ =====
print("\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿...")
oof_df = pl.read_csv(latest_oof)
print(f"  - OOFäºˆæ¸¬: {oof_df.shape}")

# å…ƒã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚‚èª­ã¿è¾¼ã¿ï¼ˆç‰¹å¾´é‡ã¨ã®çªåˆç”¨ï¼‰
train = pl.read_csv(project_root / "data" / "raw" / "train.csv", infer_schema_length=100000)
print(f"  - è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {train.shape}")

# ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
area_master = pl.read_csv(project_root / "data" / "master" / "area_master.csv")
area_master = area_master.with_columns([
    pl.col("addr1_1").cast(pl.Int64),
    pl.col("addr1_2").cast(pl.Int64),
])
print(f"  - ã‚¨ãƒªã‚¢ãƒã‚¹ã‚¿ãƒ¼: {area_master.shape}")

# ===== 2. èª¤å·®è¨ˆç®— =====
print("\nğŸ“Š èª¤å·®è¨ˆç®—...")

# èª¤å·®åˆ—ã‚’è¿½åŠ 
oof_df = oof_df.with_columns([
    (pl.col("predicted") - pl.col("actual")).alias("error"),
    ((pl.col("predicted") - pl.col("actual")).abs() / pl.col("actual") * 100).alias("ape"),  # Absolute Percentage Error
])

# åŸºæœ¬çµ±è¨ˆ
print(f"\n  èª¤å·®çµ±è¨ˆ:")
print(f"    - å¹³å‡èª¤å·® (ME): {oof_df['error'].mean():,.0f}å††")
print(f"    - å¹³å‡çµ¶å¯¾èª¤å·® (MAE): {oof_df['error'].abs().mean():,.0f}å††")
print(f"    - MAPE: {oof_df['ape'].mean():.2f}%")
print(f"    - ä¸­å¤®å€¤APE: {oof_df['ape'].median():.2f}%")

# ===== 3. äºˆæ¸¬èª¤å·®ã®åˆ†å¸ƒ =====
print("\nğŸ“ˆ äºˆæ¸¬èª¤å·®ã®åˆ†å¸ƒã‚’å¯è¦–åŒ–...")

fig, axes = plt.subplots(1, 3, figsize=(15, 4))

# APEåˆ†å¸ƒ
ax = axes[0]
ape_values = oof_df["ape"].to_numpy()
ax.hist(ape_values, bins=50, edgecolor='black', alpha=0.7)
ax.axvline(ape_values.mean(), color='red', linestyle='--', label=f'å¹³å‡: {ape_values.mean():.1f}%')
ax.axvline(np.median(ape_values), color='orange', linestyle='--', label=f'ä¸­å¤®å€¤: {np.median(ape_values):.1f}%')
ax.set_xlabel("APE (%)")
ax.set_ylabel("é »åº¦")
ax.set_title("çµ¶å¯¾ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆèª¤å·® (APE) ã®åˆ†å¸ƒ")
ax.legend()
ax.set_xlim(0, 100)

# å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤
ax = axes[1]
actual = oof_df["actual"].to_numpy()
predicted = oof_df["predicted"].to_numpy()
ax.scatter(actual, predicted, alpha=0.1, s=1)
ax.plot([0, actual.max()], [0, actual.max()], 'r--', label='y=x')
ax.set_xlabel("å®Ÿæ¸¬å€¤ (å††)")
ax.set_ylabel("äºˆæ¸¬å€¤ (å††)")
ax.set_title("å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤")
ax.legend()

# èª¤å·® vs å®Ÿæ¸¬å€¤
ax = axes[2]
ax.scatter(actual, oof_df["error"].to_numpy(), alpha=0.1, s=1)
ax.axhline(0, color='red', linestyle='--')
ax.set_xlabel("å®Ÿæ¸¬å€¤ (å††)")
ax.set_ylabel("èª¤å·® (å††)")
ax.set_title("èª¤å·® vs å®Ÿæ¸¬å€¤")

plt.tight_layout()
plt.savefig(notebook_output / "error_distribution.png", dpi=150, bbox_inches='tight')
plt.close()
print(f"  âœ“ ä¿å­˜: {notebook_output / 'error_distribution.png'}")

# ===== 4. èª¤å·®ã®å¤§ãã„ã‚µãƒ³ãƒ—ãƒ«åˆ†æ =====
print("\nğŸ” äºˆæ¸¬èª¤å·®ã®å¤§ãã„ã‚µãƒ³ãƒ—ãƒ«åˆ†æ...")

# å…ƒãƒ‡ãƒ¼ã‚¿ã¨OOFäºˆæ¸¬ã‚’çµåˆ
train_with_oof = train.with_row_index("row_id").join(
    oof_df.rename({"id": "row_id"}),
    on="row_id",
    how="left"
)

# ã‚¨ãƒªã‚¢æƒ…å ±ã‚’çµåˆ
train_with_oof = train_with_oof.with_columns([
    pl.col("addr1_1").cast(pl.Int64),
    pl.col("addr1_2").cast(pl.Int64),
])
train_with_area = train_with_oof.join(
    area_master.select(["addr1_1", "addr1_2", "éƒ½é“åºœçœŒå", "å¸‚åŒºç”ºæ‘å"]),
    on=["addr1_1", "addr1_2"],
    how="left"
)

# APEä¸Šä½10ä»¶
print("\n  APEä¸Šä½10ä»¶ï¼ˆäºˆæ¸¬ãŒå¤§ããå¤–ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ï¼‰:")
top_errors = train_with_area.sort("ape", descending=True).head(10)
for i, row in enumerate(top_errors.iter_rows(named=True)):
    print(f"    {i+1}. APE={row['ape']:.1f}% | å®Ÿæ¸¬={row['actual']:,.0f}å†† | äºˆæ¸¬={row['predicted']:,.0f}å††")
    print(f"       {row['éƒ½é“åºœçœŒå']} {row['å¸‚åŒºç”ºæ‘å']} | é¢ç©={row['house_area']}ã¡ | ç¯‰å¹´={row['year_built']}")

# ===== 5. ç‰¹å¾´é‡é‡è¦åº¦ã®å¯è¦–åŒ– =====
print("\nğŸ“Š ç‰¹å¾´é‡é‡è¦åº¦ã®å¯è¦–åŒ–...")

importance_df = pl.read_csv(latest_importance)
top_features = importance_df.head(20)

fig, ax = plt.subplots(figsize=(10, 8))
features = top_features["feature"].to_list()[::-1]
importance = top_features["importance"].to_list()[::-1]

# æ­£è¦åŒ–ï¼ˆè¦‹ã‚„ã™ãã™ã‚‹ãŸã‚ï¼‰
importance_norm = np.array(importance) / max(importance) * 100

ax.barh(features, importance_norm)
ax.set_xlabel("ç›¸å¯¾é‡è¦åº¦ (%)")
ax.set_title("ç‰¹å¾´é‡é‡è¦åº¦ Top 20")

plt.tight_layout()
plt.savefig(notebook_output / "feature_importance.png", dpi=150, bbox_inches='tight')
plt.close()
print(f"  âœ“ ä¿å­˜: {notebook_output / 'feature_importance.png'}")

# ===== 6. éƒ½é“åºœçœŒåˆ¥ã®èª¤å·®åˆ†æ =====
print("\nğŸ“Š éƒ½é“åºœçœŒåˆ¥ã®èª¤å·®åˆ†æ...")

pref_error = train_with_area.group_by("éƒ½é“åºœçœŒå").agg([
    pl.col("ape").mean().alias("mean_ape"),
    pl.col("ape").median().alias("median_ape"),
    pl.len().alias("count"),
]).sort("mean_ape", descending=True)

print("\n  éƒ½é“åºœçœŒåˆ¥ å¹³å‡APE (ä¸Šä½10):")
for i, row in enumerate(pref_error.head(10).iter_rows(named=True)):
    print(f"    {i+1}. {row['éƒ½é“åºœçœŒå']}: {row['mean_ape']:.2f}% (n={row['count']:,})")

print("\n  éƒ½é“åºœçœŒåˆ¥ å¹³å‡APE (ä¸‹ä½10):")
for i, row in enumerate(pref_error.tail(10).iter_rows(named=True)):
    print(f"    {i+1}. {row['éƒ½é“åºœçœŒå']}: {row['mean_ape']:.2f}% (n={row['count']:,})")

# éƒ½é“åºœçœŒåˆ¥APEã®å¯è¦–åŒ–
fig, ax = plt.subplots(figsize=(12, 8))
pref_sorted = pref_error.sort("mean_ape", descending=False)
prefs = pref_sorted["éƒ½é“åºœçœŒå"].to_list()
apes = pref_sorted["mean_ape"].to_list()

colors = ['red' if ape > 30 else 'orange' if ape > 28 else 'green' for ape in apes]
ax.barh(prefs, apes, color=colors)
ax.axvline(28.26, color='blue', linestyle='--', label='å…¨ä½“å¹³å‡ (28.26%)')
ax.set_xlabel("å¹³å‡ APE (%)")
ax.set_title("éƒ½é“åºœçœŒåˆ¥ å¹³å‡APE")
ax.legend()

plt.tight_layout()
plt.savefig(notebook_output / "prefecture_ape.png", dpi=150, bbox_inches='tight')
plt.close()
print(f"  âœ“ ä¿å­˜: {notebook_output / 'prefecture_ape.png'}")

# ===== 7. å¸‚åŒºç”ºæ‘åˆ¥ã®èª¤å·®åˆ†æï¼ˆä¸Šä½ãƒ»ä¸‹ä½ï¼‰ =====
print("\nğŸ“Š å¸‚åŒºç”ºæ‘åˆ¥ã®èª¤å·®åˆ†æ...")

city_error = train_with_area.group_by(["éƒ½é“åºœçœŒå", "å¸‚åŒºç”ºæ‘å"]).agg([
    pl.col("ape").mean().alias("mean_ape"),
    pl.col("ape").median().alias("median_ape"),
    pl.len().alias("count"),
]).filter(pl.col("count") >= 100).sort("mean_ape", descending=True)  # ã‚µãƒ³ãƒ—ãƒ«100ä»¶ä»¥ä¸Š

print("\n  å¸‚åŒºç”ºæ‘åˆ¥ å¹³å‡APE (ä¸Šä½10ã€n>=100):")
for i, row in enumerate(city_error.head(10).iter_rows(named=True)):
    print(f"    {i+1}. {row['éƒ½é“åºœçœŒå']} {row['å¸‚åŒºç”ºæ‘å']}: {row['mean_ape']:.2f}% (n={row['count']:,})")

print("\n  å¸‚åŒºç”ºæ‘åˆ¥ å¹³å‡APE (ä¸‹ä½10ã€n>=100):")
for i, row in enumerate(city_error.tail(10).iter_rows(named=True)):
    print(f"    {i+1}. {row['éƒ½é“åºœçœŒå']} {row['å¸‚åŒºç”ºæ‘å']}: {row['mean_ape']:.2f}% (n={row['count']:,})")

# ===== 8. ä¾¡æ ¼å¸¯åˆ¥ã®èª¤å·®åˆ†æ =====
print("\nğŸ“Š ä¾¡æ ¼å¸¯åˆ¥ã®èª¤å·®åˆ†æ...")

# ä¾¡æ ¼å¸¯ã‚’ä½œæˆï¼ˆmoney_roomã¯å††å˜ä½ã€æœ€å°490ä¸‡å††ã€œæœ€å¤§1.88å„„å††ï¼‰
train_with_area = train_with_area.with_columns([
    pl.when(pl.col("actual") < 10_000_000).then(pl.lit("~1000ä¸‡"))
    .when(pl.col("actual") < 15_000_000).then(pl.lit("1000~1500ä¸‡"))
    .when(pl.col("actual") < 20_000_000).then(pl.lit("1500~2000ä¸‡"))
    .when(pl.col("actual") < 30_000_000).then(pl.lit("2000~3000ä¸‡"))
    .when(pl.col("actual") < 50_000_000).then(pl.lit("3000~5000ä¸‡"))
    .otherwise(pl.lit("5000ä¸‡~"))
    .alias("price_range")
])

price_error = train_with_area.group_by("price_range").agg([
    pl.col("ape").mean().alias("mean_ape"),
    pl.col("ape").median().alias("median_ape"),
    pl.len().alias("count"),
]).sort("mean_ape", descending=True)

print("\n  ä¾¡æ ¼å¸¯åˆ¥ å¹³å‡APE:")
for row in price_error.iter_rows(named=True):
    print(f"    {row['price_range']}: {row['mean_ape']:.2f}% (ä¸­å¤®å€¤: {row['median_ape']:.2f}%, n={row['count']:,})")

# ===== 9. ç¯‰å¹´æ•°åˆ¥ã®èª¤å·®åˆ†æ =====
print("\nğŸ“Š ç¯‰å¹´æ•°åˆ¥ã®èª¤å·®åˆ†æ...")

# ç¯‰å¹´ã‚’æŠ½å‡ºï¼ˆyear_builtã¯ YYYYMMå½¢å¼ã€ä¾‹: 199211 â†’ 1992å¹´ï¼‰
train_with_area = train_with_area.with_columns([
    (pl.col("year_built") // 100).alias("built_year")
])

# ç¯‰å¹´æ•°ã‚’è¨ˆç®—ï¼ˆ2024å¹´åŸºæº–ï¼‰
train_with_area = train_with_area.with_columns([
    (2024 - pl.col("built_year")).alias("building_age")
])

# ç¯‰å¹´æ•°å¸¯ã‚’ä½œæˆ
train_with_area = train_with_area.with_columns([
    pl.when(pl.col("building_age") < 5).then(pl.lit("~5å¹´"))
    .when(pl.col("building_age") < 10).then(pl.lit("5~10å¹´"))
    .when(pl.col("building_age") < 20).then(pl.lit("10~20å¹´"))
    .when(pl.col("building_age") < 30).then(pl.lit("20~30å¹´"))
    .when(pl.col("building_age") < 40).then(pl.lit("30~40å¹´"))
    .otherwise(pl.lit("40å¹´~"))
    .alias("age_range")
])

age_error = train_with_area.group_by("age_range").agg([
    pl.col("ape").mean().alias("mean_ape"),
    pl.col("ape").median().alias("median_ape"),
    pl.len().alias("count"),
]).sort("mean_ape", descending=True)

print("\n  ç¯‰å¹´æ•°å¸¯åˆ¥ å¹³å‡APE:")
for row in age_error.iter_rows(named=True):
    print(f"    {row['age_range']}: {row['mean_ape']:.2f}% (ä¸­å¤®å€¤: {row['median_ape']:.2f}%, n={row['count']:,})")

# ===== 10. ã‚µãƒãƒªãƒ¼ =====
print("\n" + "=" * 60)
print("ğŸ“‹ EDA ã‚µãƒãƒªãƒ¼")
print("=" * 60)

print(f"""
ã€ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã€‘
  - CV MAPE: 28.26%
  - ç‰¹å¾´é‡æ•°: 84å€‹ï¼ˆé™¤å¤–: 46å€‹ï¼‰

ã€èª¤å·®å‚¾å‘ã€‘
  - é«˜APEéƒ½é“åºœçœŒ: é«˜çŸ¥çœŒã€æ²–ç¸„çœŒã€é³¥å–çœŒãªã©
  - ä½APEéƒ½é“åºœçœŒ: æ±äº¬éƒ½ã€ç¥å¥ˆå·çœŒã€å¤§é˜ªåºœãªã©ï¼ˆå¤§éƒ½å¸‚åœï¼‰
  - é«˜ä¾¡æ ¼å¸¯ã»ã©äºˆæ¸¬ãŒé›£ã—ã„å‚¾å‘

ã€é‡è¦ç‰¹å¾´é‡ Top 5ã€‘
  1. house_areaï¼ˆå°‚æœ‰é¢ç©ï¼‰
  2. post1ï¼ˆéƒµä¾¿ç•ªå·ä¸Š3æ¡ï¼‰
  3. year_builtï¼ˆç¯‰å¹´ï¼‰
  4. money_kyouekiï¼ˆå…±ç›Šè²»ï¼‰
  5. addr1_2ï¼ˆå¸‚åŒºç”ºæ‘ã‚³ãƒ¼ãƒ‰ï¼‰

ã€æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å€™è£œã€‘
  1. åœ°åŸŸç‰¹æ€§ã‚’åæ˜ ã—ãŸç‰¹å¾´é‡è¿½åŠ ï¼ˆéƒ½é“åºœçœŒãƒ€ãƒŸãƒ¼ç­‰ï¼‰
  2. ä¾¡æ ¼å¸¯åˆ¥ã®ãƒ¢ãƒ‡ãƒ«åˆ†å‰²æ¤œè¨
  3. ç¯‰å¹´æ•°ã®éç·šå½¢å¤‰æ›
  4. å¤–ã‚Œå€¤ï¼ˆé«˜APEï¼‰ã‚µãƒ³ãƒ—ãƒ«ã®è©³ç´°åˆ†æ
""")

print("=" * 60)
print("âœ… EDAå®Œäº†")
print("=" * 60)
