# 損失関数の工夫メモ

exp010以降で試す価値のある損失関数改善案。

---

## 現状の設定

- **ターゲット変換**: `log1p(price)`
- **目的関数**: `l2`（MSE）
- **評価指標**: MAPE（コード内で手動計算）

log空間でのMSE最適化は、元スケールでの相対誤差を近似的に最小化する。ただしMAPEと完全一致ではない（二乗 vs 絶対値のギャップ）。

---

## 改善案

### 案1: サンプル重み付け（最も簡単）

低価格帯に高い重みを付与。

- 方法: `sample_weight = 1 / y_train` または `低価格帯を2倍`
- 実装: `model.fit()` に `sample_weight` を渡すだけ
- 期待効果: 低価格帯の精度向上

---

### 案2: MAPE目的関数（カスタム）

MAPEを直接最適化。

- 方法: 勾配とヘシアンを自分で定義
- 実装: カスタム目的関数を書く
- 期待効果: 評価指標と最適化対象の完全一致

---

### 案3: Huber Loss

MSEとMAEのハイブリッド。

- 小さい誤差 → MSE的（細かく最適化）
- 大きい誤差 → MAE的（外れ値に引っ張られない）
- 実装: `objective: "huber"`, `huber_delta: 1.0` を指定
- 期待効果: 外れ値の影響緩和

---

### 案4: Quantile Loss

中央値予測（外れ値に強い）。

- α=0.5 → 中央値予測
- 過小予測と過大予測を非対称にペナルティ
- 実装: `objective: "quantile"`, `alpha: 0.5` を指定
- 期待効果: 外れ値に強い安定した予測

---

### 案5: Focal Loss風（カスタム）

難しいサンプルを重視。

- 重み = (相対誤差)^γ で動的に調整
- 相対誤差が大きいサンプルに集中学習
- 実装: カスタム目的関数を書く
- 期待効果: 低価格帯・広面積×築古の精度向上

---

## アンサンブル案

異なる損失関数のモデルを組み合わせる：

| モデル | 得意帯 |
|--------|--------|
| log + MSE（現在） | 低〜中価格帯 |
| 元スケールMSE | 高価格帯 |

単純平均でも効果が出る可能性あり。

---

## 実装優先度

| 案 | 実装コスト | 期待効果 | 優先度 |
|----|-----------|----------|--------|
| 案1: サンプル重み | 小 | 中 | 高（まず試す） |
| 案3: Huber | 小 | 小〜中 | 高（パラメータ指定のみ） |
| 案4: Quantile | 小 | 小〜中 | 中 |
| 案2: MAPE目的関数 | 中 | 大 | 中 |
| 案5: Focal風 | 中 | 中〜大 | 低（案2の後） |

---

## 参考: experiment.yaml での設定例

```yaml
# Huber
model:
  params:
    objective: "huber"
    huber_delta: 1.0

# Quantile
model:
  params:
    objective: "quantile"
    alpha: 0.5
```

---

**作成日**: 2025-11-27
