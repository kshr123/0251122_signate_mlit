"""
ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã‚·ãƒ³ãƒ—ãƒ«ãƒ»é«˜é€Ÿãƒ»å†ç¾æ€§ç¢ºä¿ã‚’å„ªå…ˆã—ãŸãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
"""

import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import mlflow
import polars as pl
import lightgbm as lgb
import numpy as np
from pathlib import Path
from datetime import datetime
from sklearn.model_selection import KFold

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from data.loader import DataLoader
from preprocessing.simple import SimplePreprocessor
from features.base import set_seed
from evaluation.metrics import calculate_mape
from training.utils.mlflow_helper import (
    log_dataset_info,
    log_cv_results,
    log_feature_list,
    log_model_params,
)
from utils.config import load_config


# ===== è¨­å®š =====
SEED = 42
N_SPLITS = 3
NUM_BOOST_ROUND = 100


def train_baseline():
    """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"""

    # ã‚·ãƒ¼ãƒ‰å›ºå®š
    set_seed(SEED)

    # MLflowå®Ÿé¨“è¨­å®š
    mlflow.set_experiment("signate_mlit_rental_price")

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_name = f"baseline_{timestamp}"

    with mlflow.start_run(run_name=run_name):
        print(f"ğŸš€ è¨“ç·´é–‹å§‹: {run_name}")

        # ===== ã‚¿ã‚°è¨­å®š =====
        mlflow.set_tag("experiment_type", "baseline")
        mlflow.set_tag("model_family", "gbdt")
        mlflow.set_tag("status", "running")

        # ===== ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨˜éŒ² =====
        mlflow.log_param("seed", SEED)
        mlflow.log_param("model_type", "LightGBM")
        mlflow.log_param("n_splits", N_SPLITS)
        mlflow.log_param("num_boost_round", NUM_BOOST_ROUND)

        # ===== ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ =====
        print("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
        config = load_config("data", config_dir="03_configs")
        loader = DataLoader(config, add_address_columns=False)

        train = loader.load_train()
        test = loader.load_test()

        print(f"  - Train: {train.shape}")
        print(f"  - Test: {test.shape}")

        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã‚’è¨˜éŒ²
        log_dataset_info(train, prefix="train")
        log_dataset_info(test, prefix="test")

        # ===== å‰å‡¦ç† =====
        print("ğŸ”§ å‰å‡¦ç†ä¸­...")
        preprocessor = SimplePreprocessor(
            cardinality_threshold=50,
            fill_missing=False,  # LightGBMãŒæ¬ æå€¤ã‚’è‡ªå‹•å‡¦ç†
        )

        # fitã¯trainã®ã¿ã§å®Ÿè¡Œ
        X_train = preprocessor.fit_transform(train)
        y_train = train["money_room"].to_numpy()

        X_test = preprocessor.transform(test)

        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡ã®åå‰ãƒªã‚¹ãƒˆï¼ˆå¾Œã§ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«ä½¿ç”¨ï¼‰
        categorical_features = [
            col for col in preprocessor.low_cardinality_cols
            if col in preprocessor.feature_cols
        ]

        print(f"  - ç‰¹å¾´é‡æ•°: {len(preprocessor.feature_cols)}")
        print(f"  - æ•°å€¤ç‰¹å¾´é‡: {len(preprocessor.numeric_cols)}")
        print(f"  - ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ç‰¹å¾´é‡: {len(preprocessor.low_cardinality_cols)}")

        # ç‰¹å¾´é‡æƒ…å ±ã‚’è¨˜éŒ²
        mlflow.log_param("n_features", len(preprocessor.feature_cols))
        mlflow.log_param("n_numeric_features", len(preprocessor.numeric_cols))
        mlflow.log_param("n_categorical_features", len(preprocessor.low_cardinality_cols))

        # ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ä¿å­˜
        log_feature_list(preprocessor.feature_cols, artifact_path="features.txt")

        # ===== ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆ3-Fold CVï¼‰ =====
        print("ğŸŒ² ãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸­ï¼ˆ3-Fold CVï¼‰...")

        # LightGBMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        params = {
            "objective": "regression",
            "metric": "mape",
            "boosting": "gbdt",
            "learning_rate": 0.05,
            "num_leaves": 31,
            "max_depth": -1,
            "min_child_samples": 20,
            "subsample": 0.8,
            "subsample_freq": 1,
            "colsample_bytree": 0.8,
            "reg_alpha": 0.0,
            "reg_lambda": 0.0,
            "random_state": SEED,
            "verbose": -1,
            "force_row_wise": True,
        }

        log_model_params(params)
        mlflow.log_param("early_stopping_rounds", 100)

        # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)
        cv_scores = []
        oof_predictions = np.zeros(len(y_train))
        models = []

        # Polars â†’ pandaså¤‰æ›ï¼ˆLightGBMç”¨ï¼‰
        # trainã¨testã§å‹ãŒç•°ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ä¸¡æ–¹ã§æ–‡å­—åˆ—å‹ã‚’æ¤œå‡ºã—ã¦å¤‰æ›
        string_cols_train = [col for col in X_train.columns if X_train[col].dtype == pl.Utf8]
        string_cols_test = [col for col in X_test.columns if X_test[col].dtype == pl.Utf8]
        string_cols = list(set(string_cols_train + string_cols_test))

        print(f"  - Trainæ–‡å­—åˆ—å‹: {string_cols_train}")
        print(f"  - Testæ–‡å­—åˆ—å‹: {string_cols_test}")

        # ã™ã¹ã¦ã®æ–‡å­—åˆ—å‹ã‚«ãƒ©ãƒ ã‚’æ•°å€¤ã«å¤‰æ›
        for col in string_cols:
            if col in X_train.columns and X_train[col].dtype == pl.Utf8:
                X_train = X_train.with_columns(
                    pl.col(col).cast(pl.Categorical).to_physical().alias(col)
                )
            if col in X_test.columns and X_test[col].dtype == pl.Utf8:
                X_test = X_test.with_columns(
                    pl.col(col).cast(pl.Categorical).to_physical().alias(col)
                )

        X_train_pd = X_train.to_pandas()
        X_test_pd = X_test.to_pandas()

        for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_train_pd)):
            print(f"  - Fold {fold_idx + 1}/{N_SPLITS}")

            # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
            X_tr = X_train_pd.iloc[train_idx]
            y_tr = y_train[train_idx]
            X_val = X_train_pd.iloc[val_idx]
            y_val = y_train[val_idx]

            # LightGBM Datasetä½œæˆ
            train_data = lgb.Dataset(
                X_tr,
                label=y_tr,
                categorical_feature=categorical_features,
            )
            val_data = lgb.Dataset(
                X_val,
                label=y_val,
                categorical_feature=categorical_features,
                reference=train_data,
            )

            # è¨“ç·´ï¼ˆEarly Stoppingä»˜ãï¼‰
            callbacks = [
                lgb.early_stopping(stopping_rounds=100, verbose=False),
                lgb.log_evaluation(period=0),  # ãƒ­ã‚°å‡ºåŠ›ãªã—
            ]

            model = lgb.train(
                params,
                train_data,
                num_boost_round=NUM_BOOST_ROUND,
                valid_sets=[train_data, val_data],
                valid_names=["train", "valid"],
                callbacks=callbacks,
            )

            models.append(model)

            # Validationäºˆæ¸¬
            y_pred = model.predict(X_val, num_iteration=model.best_iteration)
            oof_predictions[val_idx] = y_pred

            # MAPEè¨ˆç®—
            fold_mape = calculate_mape(y_val, y_pred)
            cv_scores.append(fold_mape)

            print(f"    MAPE: {fold_mape:.4f}% (best_iteration: {model.best_iteration})")

        cv_scores = np.array(cv_scores)

        # CVçµæœã‚’è¨˜éŒ²
        log_cv_results(cv_scores, metric_name="mape")

        print(f"\nğŸ“Š CVçµæœ:")
        print(f"  - MAPE: {cv_scores.mean():.4f}% Â± {cv_scores.std():.4f}%")
        print(f"  - Min: {cv_scores.min():.4f}%")
        print(f"  - Max: {cv_scores.max():.4f}%")

        # ===== å…¨ãƒ‡ãƒ¼ã‚¿ã§å†è¨“ç·´ =====
        print("\nğŸ”„ å…¨ãƒ‡ãƒ¼ã‚¿ã§å†è¨“ç·´ä¸­...")
        full_train_data = lgb.Dataset(
            X_train_pd,
            label=y_train,
            categorical_feature=categorical_features,
        )

        final_model = lgb.train(
            params,
            full_train_data,
            num_boost_round=NUM_BOOST_ROUND,
        )

        # ===== æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ =====
        print("ğŸ“ æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆä¸­...")
        test_predictions = final_model.predict(X_test_pd, num_iteration=final_model.best_iteration)

        submission = test.select("id").with_columns(
            pl.Series("money_room", test_predictions)
        )

        # 06_experiments/exp001_baseline/é…ä¸‹ã«ä¿å­˜
        exp_dir = Path("06_experiments/exp001_baseline")
        exp_dir.mkdir(parents=True, exist_ok=True)

        submission_path = exp_dir / f"submission_{timestamp}.csv"
        submission.write_csv(submission_path, include_header=False)

        print(f"  - ä¿å­˜å…ˆ: {submission_path}")

        # æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã¨ã—ã¦ä¿å­˜
        mlflow.log_artifact(str(submission_path))

        # ===== ãƒ¢ãƒ‡ãƒ«ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ =====
        mlflow.lightgbm.log_model(final_model, "model")

        # ===== å®Œäº† =====
        mlflow.set_tag("status", "completed")

        print(f"\nâœ… è¨“ç·´å®Œäº†!")
        print(f"  - Run ID: {mlflow.active_run().info.run_id}")
        print(f"  - CV MAPE: {cv_scores.mean():.4f}% Â± {cv_scores.std():.4f}%")
        print(f"  - æå‡ºãƒ•ã‚¡ã‚¤ãƒ«: {submission_path}")


if __name__ == "__main__":
    train_baseline()
