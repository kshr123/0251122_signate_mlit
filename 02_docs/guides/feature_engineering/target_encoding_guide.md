# Target Encoding å®Œå…¨ã‚¬ã‚¤ãƒ‰

> ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆçµ±è¨ˆé‡ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹å¼·åŠ›ãªæ‰‹æ³•

---

## ğŸ“– Target Encodingã¨ã¯

**å®šç¾©**: ã‚«ãƒ†ã‚´ãƒªã‚’**ãã®ã‚«ãƒ†ã‚´ãƒªã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¹³å‡å€¤**ã§ç½®ãæ›ãˆã‚‹æ‰‹æ³•

**åˆ¥å**: Mean Encoding, Likelihood Encoding

**ç‰¹å¾´**:
- ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’**1æ¬¡å…ƒã®æ•°å€¤**ã«å¤‰æ›
- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã®**é–¢ä¿‚æ€§ã‚’ç›´æ¥ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰**
- é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£å¤‰æ•°ã«ç‰¹ã«æœ‰åŠ¹

---

## ğŸ”‘ åŸºæœ¬åŸç†

### ä»•çµ„ã¿

```python
# å…ƒãƒ‡ãƒ¼ã‚¿
room_count | money_room (target)
-----------|-------------------
    1      |   50,000
    1      |   55,000
    2      |   80,000
    2      |   85,000
    3      |  120,000
    3      |  125,000

# Step 1: ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¹³å‡ã‚’è¨ˆç®—
room_count | mean_target
-----------|-------------
    1      |   52,500
    2      |   82,500
    3      |  122,500

# Step 2: ã‚«ãƒ†ã‚´ãƒªã‚’å¹³å‡å€¤ã§ç½®ãæ›ãˆ
room_count_encoded | money_room
-------------------|------------
     52,500        |   50,000
     52,500        |   55,000
     82,500        |   80,000
     82,500        |   85,000
    122,500        |  120,000
    122,500        |  125,000

# ã“ã‚Œã‚’ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ç”¨
```

### ãªãœæœ‰åŠ¹ã‹ï¼Ÿ

```python
# ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®ã¾ã¾
room_count = [1, 2, 3, 4]
# ãƒ¢ãƒ‡ãƒ«ã¯ã€Œ1 < 2 < 3 < 4ã€ã¨ã„ã†å¤§å°é–¢ä¿‚ã—ã‹å­¦ç¿’ã§ããªã„

# Target Encodingå¾Œ
room_count_encoded = [52500, 82500, 122500, 182500]
# ãƒ¢ãƒ‡ãƒ«ã¯ã€Œ1éƒ¨å±‹ã¯å®‰ã„ã€4éƒ¨å±‹ã¯é«˜ã„ã€ã¨ã„ã†
# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã®é–¢ä¿‚ã‚’ç›´æ¥å­¦ç¿’ã§ãã‚‹

# â†’ äºˆæ¸¬ç²¾åº¦ãŒå¤§å¹…ã«å‘ä¸Šï¼
```

---

## âš™ï¸ å®Ÿè£…æ–¹æ³•

### åŸºæœ¬å®Ÿè£…ï¼ˆãƒŠã‚¤ãƒ¼ãƒ–ç‰ˆï¼‰

```python
import polars as pl

def target_encode_naive(
    df: pl.DataFrame,
    cat_col: str,
    target_col: str
) -> pl.DataFrame:
    """
    ãƒŠã‚¤ãƒ¼ãƒ–ãªTarget Encodingï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰

    âš ï¸ è­¦å‘Š: ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ï¼ˆéå­¦ç¿’ï¼‰ãŒç™ºç”Ÿã™ã‚‹ãŸã‚æœ¬ç•ªã§ã¯ä½¿ç”¨ä¸å¯
    """
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥å¹³å‡ã‚’è¨ˆç®—
    cat_means = (
        df.group_by(cat_col)
        .agg(pl.col(target_col).mean().alias(f"{cat_col}_te"))
    )

    # å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«ãƒãƒ¼ã‚¸
    df_encoded = df.join(cat_means, on=cat_col, how='left')

    return df_encoded

# ä½¿ç”¨ä¾‹
train = pl.DataFrame({
    'room_count': [1, 1, 2, 2, 3, 3],
    'money_room': [50000, 55000, 80000, 85000, 120000, 125000]
})

train_encoded = target_encode_naive(train, 'room_count', 'money_room')
print(train_encoded)
```

### æ­£ã—ã„å®Ÿè£…ï¼ˆã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç‰ˆï¼‰

```python
from sklearn.model_selection import KFold
import numpy as np

def target_encode_cv(
    df: pl.DataFrame,
    cat_col: str,
    target_col: str,
    n_folds: int = 5,
    alpha: float = 10.0
) -> pl.Series:
    """
    ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½¿ã£ãŸæ­£ã—ã„Target Encoding

    Args:
        df: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        cat_col: ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ©ãƒ 
        target_col: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚«ãƒ©ãƒ 
        n_folds: Foldæ•°
        alpha: æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ï¼‰

    Returns:
        ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸå€¤ã®Series
    """
    encoded = np.zeros(len(df))
    global_mean = df[target_col].mean()

    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)

    for train_idx, val_idx in kf.split(df):
        # è¨“ç·´Foldã§å¹³å‡ã‚’è¨ˆç®—
        train_fold = df[train_idx]

        cat_stats = (
            train_fold.group_by(cat_col)
            .agg([
                pl.col(target_col).mean().alias('mean'),
                pl.col(target_col).count().alias('count')
            ])
        )

        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³Foldã«é©ç”¨
        val_fold = df[val_idx]

        for row_idx, cat_value in enumerate(val_fold[cat_col]):
            # ã‚«ãƒ†ã‚´ãƒªã®çµ±è¨ˆé‡ã‚’å–å¾—
            stats = cat_stats.filter(pl.col(cat_col) == cat_value)

            if stats.height > 0:
                mean = stats['mean'][0]
                count = stats['count'][0]

                # ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°é©ç”¨
                smoothed = (count * mean + alpha * global_mean) / (count + alpha)
                encoded[val_idx[row_idx]] = smoothed
            else:
                # æœªçŸ¥ã‚«ãƒ†ã‚´ãƒªã¯å…¨ä½“å¹³å‡
                encoded[val_idx[row_idx]] = global_mean

    return pl.Series(f"{cat_col}_te", encoded)

# ä½¿ç”¨ä¾‹
train['room_count_te'] = target_encode_cv(
    train,
    cat_col='room_count',
    target_col='money_room',
    n_folds=5
)
```

### ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¸ã®é©ç”¨

```python
def apply_target_encoding(
    train: pl.DataFrame,
    test: pl.DataFrame,
    cat_col: str,
    target_col: str,
    alpha: float = 10.0
) -> tuple[pl.DataFrame, pl.DataFrame]:
    """
    è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§Target Encodingã‚’å­¦ç¿’ã—ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«é©ç”¨

    Args:
        train: è¨“ç·´ãƒ‡ãƒ¼ã‚¿
        test: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        cat_col: ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ©ãƒ 
        target_col: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚«ãƒ©ãƒ 
        alpha: ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

    Returns:
        (train_encoded, test_encoded)
    """
    global_mean = train[target_col].mean()

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§çµ±è¨ˆé‡ã‚’è¨ˆç®—
    cat_stats = (
        train.group_by(cat_col)
        .agg([
            pl.col(target_col).mean().alias('mean'),
            pl.col(target_col).count().alias('count')
        ])
    )

    # ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°é©ç”¨
    cat_stats = cat_stats.with_columns(
        ((pl.col('count') * pl.col('mean') + alpha * global_mean) / (pl.col('count') + alpha))
        .alias(f"{cat_col}_te")
    )

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«ãƒãƒ¼ã‚¸ï¼ˆã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç‰ˆã‚’ä½¿ç”¨æ¨å¥¨ï¼‰
    train_encoded = train.join(
        cat_stats.select([cat_col, f"{cat_col}_te"]),
        on=cat_col,
        how='left'
    )

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«ãƒãƒ¼ã‚¸
    test_encoded = test.join(
        cat_stats.select([cat_col, f"{cat_col}_te"]),
        on=cat_col,
        how='left'
    )

    # æœªçŸ¥ã‚«ãƒ†ã‚´ãƒªã¯å…¨ä½“å¹³å‡ã§åŸ‹ã‚ã‚‹
    test_encoded = test_encoded.with_columns(
        pl.col(f"{cat_col}_te").fill_null(global_mean)
    )

    return train_encoded, test_encoded
```

---

## âœ… ãƒ¡ãƒªãƒƒãƒˆ

### 1. é«˜ã„äºˆæ¸¬ç²¾åº¦

```python
# ã‚«ãƒ†ã‚´ãƒªã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®é–¢ä¿‚ã‚’ç›´æ¥æ•°å€¤åŒ–
# â†’ ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã—ã‚„ã™ã„
# â†’ ç‰¹ã«Tree-basedãƒ¢ãƒ‡ãƒ«ï¼ˆLightGBMã€XGBoostï¼‰ã§åŠ¹æœå¤§
```

### 2. æ¬¡å…ƒæ•°ãŒå¢—ãˆãªã„

```python
# One-Hot Encoding
# 47éƒ½é“åºœçœŒ â†’ 47æ¬¡å…ƒ

# Target Encoding
# 47éƒ½é“åºœçœŒ â†’ 1æ¬¡å…ƒ

# â†’ ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ã„
# â†’ å­¦ç¿’é€Ÿåº¦ãŒé€Ÿã„
```

### 3. é«˜ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã«å¯¾å¿œ

```python
# building_nameï¼ˆ69,370ç¨®é¡ï¼‰

# One-Hot: ä¸å¯èƒ½ï¼ˆæ¬¡å…ƒçˆ†ç™ºï¼‰
# Target Encoding: å¯èƒ½ï¼ˆ1æ¬¡å…ƒï¼‰
```

### 4. é †åºé–¢ä¿‚ã‚’ä¿æŒ

```python
# 1éƒ¨å±‹: 52,500å††
# 2éƒ¨å±‹: 82,500å††
# 3éƒ¨å±‹: 122,500å††

# â†’ è‡ªç„¶ãªé †åºé–¢ä¿‚ãŒæ•°å€¤ã«åæ˜ ã•ã‚Œã‚‹
```

---

## âŒ ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã¨å¯¾ç­–

### 1. ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ï¼ˆéå­¦ç¿’ï¼‰

**å•é¡Œ**:
```python
# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ç›´æ¥ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹ã¨...
train['room_count_te'] = train.group_by('room_count')['money_room'].mean()

# â†’ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã¯å®Œç’§ã«äºˆæ¸¬ã§ãã‚‹
# â†’ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã¯ç²¾åº¦ãŒä¸‹ãŒã‚‹ï¼ˆéå­¦ç¿’ï¼‰
```

**å¯¾ç­–**:
```python
# ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
# â†’ å„Foldã§ã¯ã€Œä»–ã®Foldã®å¹³å‡ã€ã‚’ä½¿ã†
# â†’ ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã‚’é˜²ã

encoded = target_encode_cv(train, 'room_count', 'money_room', n_folds=5)
```

### 2. æœªçŸ¥ã‚«ãƒ†ã‚´ãƒª

**å•é¡Œ**:
```python
# è¨“ç·´ãƒ‡ãƒ¼ã‚¿: room_count = [1, 2, 3, 4]
# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: room_count = [1, 2, 3, 5]  # 5ã¯æœªçŸ¥

# â†’ 5éƒ¨å±‹ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å€¤ãŒãªã„
```

**å¯¾ç­–**:
```python
# å…¨ä½“å¹³å‡ã§åŸ‹ã‚ã‚‹
global_mean = train['money_room'].mean()

test['room_count_te'] = test['room_count'].map(encoding_dict)
test['room_count_te'] = test['room_count_te'].fill_null(global_mean)
```

### 3. ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„ã‚«ãƒ†ã‚´ãƒª

**å•é¡Œ**:
```python
# 28éƒ¨å±‹: ã‚µãƒ³ãƒ—ãƒ«æ•°12ä»¶ã€å¹³å‡1.5å„„å††
# â†’ ã‚µãƒ³ãƒ—ãƒ«ãŒå°‘ãªãã€å¹³å‡ãŒä¸å®‰å®š

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§å¤§ããç•°ãªã‚‹å¯èƒ½æ€§
```

**å¯¾ç­–**:
```python
# ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆBayesianå¹³å‡ï¼‰
# ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„ã‚«ãƒ†ã‚´ãƒªã¯å…¨ä½“å¹³å‡ã«è¿‘ã¥ã‘ã‚‹

smoothed = (count * category_mean + alpha * global_mean) / (count + alpha)

# alpha=10ã®å ´åˆ:
# ã‚µãƒ³ãƒ—ãƒ«æ•°12ä»¶ â†’ å…¨ä½“å¹³å‡ã®å½±éŸ¿ ç´„45%
# ã‚µãƒ³ãƒ—ãƒ«æ•°100ä»¶ â†’ å…¨ä½“å¹³å‡ã®å½±éŸ¿ ç´„9%
```

---

## ğŸ¯ Target EncodingåŠ¹æœã®äºˆæ¸¬

### æŒ‡æ¨™ã®å®šç¾©

**Target EncodingåŠ¹æœ** = ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¹³å‡å€¤ã®æ¨™æº–åå·®

```python
def calculate_target_encoding_potential(
    df: pl.DataFrame,
    category_col: str,
    target_col: str
) -> float:
    """
    Target Encodingã®åŠ¹æœã‚’äºˆæ¸¬

    Returns:
        ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¹³å‡å€¤ã®æ¨™æº–åå·®
        ï¼ˆå€¤ãŒå¤§ãã„ã»ã©åŠ¹æœçš„ï¼‰
    """
    # ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®å¹³å‡ã‚’è¨ˆç®—
    category_means = (
        df.group_by(category_col)
        .agg(pl.col(target_col).mean().alias("mean_target"))
        .drop_nulls()
    )

    # å¹³å‡å€¤ã®æ¨™æº–åå·®
    std_of_means = category_means["mean_target"].std()

    return std_of_means
```

### è§£é‡ˆ

```python
# æ¨™æº–åå·®ãŒå¤§ãã„
# â†’ ã‚«ãƒ†ã‚´ãƒªé–“ã§ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãŒå¤§ããç•°ãªã‚‹
# â†’ Target EncodingãŒæœ‰åŠ¹
# â†’ äºˆæ¸¬ç²¾åº¦å‘ä¸ŠãŒæœŸå¾…ã§ãã‚‹

# æ¨™æº–åå·®ãŒå°ã•ã„
# â†’ ã‚«ãƒ†ã‚´ãƒªé–“ã§ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãŒã»ã¼åŒã˜
# â†’ Target Encodingã®åŠ¹æœã¯è–„ã„
```

### å®Ÿä¾‹ï¼ˆã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼‰

```python
# 04_categorical_analysis.ipynb ã®çµæœ

[Target EncodingåŠ¹æœäºˆæ¸¬ - ä¸Šä½5ä»¶]
ã‚«ãƒ©ãƒ å                | ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•° | æ¨™æº–åå·®
-----------------------|-----------|-------------
room_count             |        28 | 34,579,045  â† æœ€é«˜ï¼
madori_number_all      |        32 | 33,062,546
reform_exterior        |         7 | 17,664,376
parking_money_tax      |         5 | 16,789,196
parking_kubun          |         6 | 14,193,758

# room_count ã®è©³ç´°
room_count | count  | mean_target
-----------|--------|---------------
    28     |    12  | 150,000,000   â† 28éƒ¨å±‹: è¶…é«˜é¡
    27     |    18  | 142,000,000
    ...    |  ...   |  ...
     3     | 15,420 |  35,000,000
     2     | 45,890 |  25,000,000
     1     | 89,234 |  18,000,000   â† 1éƒ¨å±‹: å®‰ã„

# ã‚«ãƒ†ã‚´ãƒªé–“ã®å·®ãŒç´„1.3å„„å††
# â†’ Target EncodingãŒè¶…æœ‰åŠ¹ï¼
```

---

## ğŸ”¬ ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆå¹³æ»‘åŒ–ï¼‰

### æ¦‚å¿µ

ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„ã‚«ãƒ†ã‚´ãƒªã®å¹³å‡ã‚’**å…¨ä½“å¹³å‡ã«è¿‘ã¥ã‘ã‚‹**ã“ã¨ã§ã€éå­¦ç¿’ã‚’é˜²ãã€‚

### Bayesianå¹³å‡

```python
smoothed_mean = (n * category_mean + alpha * global_mean) / (n + alpha)

# n: ã‚«ãƒ†ã‚´ãƒªã®ã‚µãƒ³ãƒ—ãƒ«æ•°
# alpha: æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆä¸€èˆ¬çš„ã« 5ã€œ20ï¼‰
```

### åŠ¹æœ

```python
# ä¾‹: å…¨ä½“å¹³å‡ = 25,000,000å††

# ã‚µãƒ³ãƒ—ãƒ«æ•°100ä»¶ã€å¹³å‡30,000,000å††
smoothed = (100 * 30M + 10 * 25M) / (100 + 10)
         = (3,000M + 250M) / 110
         = 29,545,455  # ã»ã¼å…ƒã®å¹³å‡

# ã‚µãƒ³ãƒ—ãƒ«æ•°5ä»¶ã€å¹³å‡80,000,000å††ï¼ˆå¤–ã‚Œå€¤ã®å¯èƒ½æ€§ï¼‰
smoothed = (5 * 80M + 10 * 25M) / (5 + 10)
         = (400M + 250M) / 15
         = 43,333,333  # å…¨ä½“å¹³å‡ã«å¼•ãå¯„ã›ã‚‰ã‚ŒãŸ

# â†’ ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„ã»ã©å…¨ä½“å¹³å‡ã«è¿‘ã¥ã
# â†’ éå­¦ç¿’ã‚’é˜²ã
```

### alphaãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é¸ã³æ–¹

```python
# alpha = 0: ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ãªã—ï¼ˆéå­¦ç¿’ãƒªã‚¹ã‚¯å¤§ï¼‰
# alpha = 5: å¼±ã„ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
# alpha = 10: ä¸­ç¨‹åº¦ã®ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆæ¨å¥¨ï¼‰
# alpha = 20: å¼·ã„ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
# alpha = 100: éå¸¸ã«å¼·ã„ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆå…¨ä½“å¹³å‡ã«è¿‘ã¥ãã™ãï¼‰

# ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã§æœ€é©å€¤ã‚’æ¢ã™
for alpha in [5, 10, 15, 20]:
    encoded = target_encode_cv(train, 'room_count', 'money_room', alpha=alpha)
    score = cross_val_score(model, encoded, y, cv=5).mean()
    print(f"alpha={alpha}: {score:.4f}")
```

---

## ğŸ’¡ å®Ÿè·µçš„ãªTips

### Tip 1: è¤‡æ•°ã®Targetçµ±è¨ˆé‡ã‚’ä½¿ã†

```python
# å¹³å‡ã ã‘ã§ãªãã€ä»–ã®çµ±è¨ˆé‡ã‚‚ç‰¹å¾´é‡ã«

cat_stats = df.group_by('room_count').agg([
    pl.col('money_room').mean().alias('room_count_mean'),    # å¹³å‡
    pl.col('money_room').median().alias('room_count_median'),  # ä¸­å¤®å€¤
    pl.col('money_room').std().alias('room_count_std'),      # æ¨™æº–åå·®
    pl.col('money_room').min().alias('room_count_min'),      # æœ€å°å€¤
    pl.col('money_room').max().alias('room_count_max'),      # æœ€å¤§å€¤
    pl.col('money_room').count().alias('room_count_count')   # ä»¶æ•°
])

# ã™ã¹ã¦ã‚’ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ã†
# â†’ ãƒ¢ãƒ‡ãƒ«ãŒã‚ˆã‚Šè±Šå¯Œãªæƒ…å ±ã‚’å­¦ç¿’
```

### Tip 2: ã‚«ãƒ†ã‚´ãƒªçµ„ã¿åˆã‚ã›ã®Target Encoding

```python
# å˜ä¸€ã‚«ãƒ†ã‚´ãƒªã ã‘ã§ãªãã€çµ„ã¿åˆã‚ã›ã‚‚

# ä¾‹: éƒ½é“åºœçœŒ Ã— å»ºç‰©æ§‹é€ 
df = df.with_columns(
    (pl.col('prefecture') + '_' + pl.col('building_structure'))
    .alias('pref_structure')
)

# pref_structure ã‚’Target Encoding
# â†’ ã‚ˆã‚Šç´°ã‹ã„ç²’åº¦ã§é–¢ä¿‚æ€§ã‚’æ‰ãˆã‚‹
```

### Tip 3: ä»–ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ã®ä½µç”¨

```python
# Target Encodingã ã‘ã§ãªãã€è¤‡æ•°æ‰‹æ³•ã‚’ä½µç”¨

df = df.with_columns([
    # Target Encoding
    pl.col('room_count').alias('room_count_te'),

    # Frequency Encoding
    pl.col('room_count')
    .value_counts()
    .struct.field('count')
    .alias('room_count_freq'),

    # One-Hot Encodingï¼ˆéƒ¨å±‹æ•°ãŒå°‘ãªã„ã®ã§å¯èƒ½ï¼‰
    # ...
])

# ãƒ¢ãƒ‡ãƒ«ãŒè‡ªå‹•çš„ã«æœ‰åŠ¹ãªç‰¹å¾´é‡ã‚’é¸æŠ
```

### Tip 4: ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥ã®çµ±ä¸€

```python
# Target Encodingã¨ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã§åŒã˜Foldåˆ†å‰²ã‚’ä½¿ã†

from sklearn.model_selection import KFold

kf = KFold(n_splits=5, shuffle=True, random_state=42)

# 1. Target Encoding
encoded = target_encode_cv(train, 'room_count', 'money_room', kf=kf)

# 2. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚‚åŒã˜Foldã§
for train_idx, val_idx in kf.split(train):
    # ...
```

---

## ğŸ“Š ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®æ´»ç”¨

### å¯¾è±¡å¤‰æ•°

```python
# Target EncodingåŠ¹æœãŒé«˜ã„å¤‰æ•°ï¼ˆä¸Šä½10ä»¶ï¼‰

ã‚«ãƒ©ãƒ å                | ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ | åŠ¹æœï¼ˆæ¨™æº–åå·®ï¼‰
-----------------------|----------------|----------------
room_count             |       28       | 34,579,045
madori_number_all      |       32       | 33,062,546
reform_exterior        |        7       | 17,664,376
parking_money_tax      |        5       | 16,789,196
parking_kubun          |        6       | 14,193,758
building_structure     |       13       | 13,389,693
building_type          |       16       | 13,074,501
genkyo_code            |        6       | 12,263,027
basement_floor_count   |       18       | 11,646,776
traffic_car            |        3       |  8,629,124
```

### å®Ÿè£…ä¾‹

```python
import polars as pl
from sklearn.model_selection import KFold

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
train = pl.read_parquet('data/processed/train.parquet')

# Target Encodingå¯¾è±¡ã‚«ãƒ©ãƒ 
te_cols = [
    'room_count',
    'madori_number_all',
    'reform_exterior',
    'parking_money_tax',
    'parking_kubun'
]

# ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§Target Encoding
target_col = 'money_room'

for col in te_cols:
    train = train.with_columns(
        target_encode_cv(train, col, target_col, n_folds=5, alpha=10)
    )

# ãƒ¢ãƒ‡ãƒªãƒ³ã‚°
from lightgbm import LGBMRegressor

# å…ƒã®ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ©ãƒ ã¨Target Encodedã‚«ãƒ©ãƒ ã®ä¸¡æ–¹ã‚’ä½¿ã†
feature_cols = te_cols + [f"{col}_te" for col in te_cols]

X = train.select(feature_cols).to_pandas()
y = train[target_col].to_numpy()

model = LGBMRegressor()
model.fit(X, y)
```

---

## ğŸ“š å‚è€ƒè³‡æ–™

### è«–æ–‡ãƒ»è¨˜äº‹

- [A Preprocessing Scheme for High-Cardinality Categorical Attributes in Classification and Prediction Problems](https://dl.acm.org/doi/10.1145/507533.507538) (Micci-Barreca, 2001)
- Kaggleã§ã®æ´»ç”¨äº‹ä¾‹å¤šæ•°ï¼ˆç‰¹ã«Click-Through Rateäºˆæ¸¬ã€åºƒå‘Šã‚³ãƒ³ãƒšç­‰ï¼‰

### å®Ÿè£…ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

- category_encoders: `TargetEncoder`
- feature-engine: `MeanEncoder`
- è‡ªä½œå®Ÿè£…æ¨å¥¨ï¼ˆã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶å¾¡ã®ãŸã‚ï¼‰

---

## ğŸ“– é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [cardinality_guide.md](./cardinality_guide.md) - ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£å®Œå…¨ã‚¬ã‚¤ãƒ‰
- [hashing_trick_guide.md](./hashing_trick_guide.md) - Hashing Trickå®Œå…¨ã‚¬ã‚¤ãƒ‰
- [04_categorical_analysis.ipynb](../05_notebooks/01_eda/04_categorical_analysis.ipynb) - Target EncodingåŠ¹æœã®åˆ†æ
- [04_src/eda/categorical.py](../04_src/eda/categorical.py) - Target EncodingåŠ¹æœè¨ˆç®—é–¢æ•°ï¼ˆTDDæ¸ˆã¿ï¼‰

---

**æœ€çµ‚æ›´æ–°**: 2025-11-23
